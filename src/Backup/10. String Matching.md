# String Matching
## Introduction
Given a pattern string, `P`, of length `M`, text string, `A`, of length `N`, do all characters in `P` match a substring of the characters in `A`, starting from some index `i`?
![[String-Matching-demo.png]]

## Brute Force Algorithm:
Start at beginning of pattern and text, compare left to right, character by character
If a mismatch occurs, restart process at:
	One position over from previous start of text(Did not match from location `k` so let's try `k+1`)
	Beginning of pattern(We must still match whole pattern)
```Java
public static int search1(String pat, String txt)
 { 
   int M = pat.length(); 
   int N = txt.length(); 
   for (int i = 0; i <= N - M; i++) 
   { 
      int j; 
      for (j = 0; j < M; j++) 
      {
        if (txt.charAt(i+j) != pat.charAt(j)) 
           break; 
      } 
      if (j == M) return i; // found at offset i 
   } 
   return N; // not found 
}
```
### Performance
In the normal case, we may mismatch right away or perhaps after a few `char` matches for each location in the text. But we may have to go through the entire text: $O(N)$

For the worst case, consider: `A=XXXXXXXXXXXXXXXXXXXXXXXXXXY` and `P = XXXXY`.
Notice that `P` must be completely compared (M `char` comps) each time we move one index down in `A`. We start text match at each of `0`, `1`, `2`, … (`N-M`) before failing. Thus, the total run-time is $M(N-M+1)=O(NM)$ when $N>>M$.

The JavaSDK uses this algorithm for `indexOf()` method with some modifications.

### Improvements
1) Improve the *worst case* performance
	This is good theoretically, but in reality the worst case does not occur very often for ASCII strings. However, for binary strings it may be more important.
2) Improve the *normal case* performance
	This will be very helpful, especially for searches in long files

## Rabin Karp
Let's try a different approach. Recall that we found hashing as a way of efficiently accessing data. Can we apply this to string matching? Consider the hash function we discussed for strings:
$$s[0]*B^{n-1} + s[1]*B^{n-2} + … + s[n-2]*B^1 + s[n-1]$$
- where $B$ is some integer
- $B$ = 31 in JDK
- Recall that we said that if B == number of characters in the character set, the result would be unique for all strings (if we can store it)
Thus, if the **integer values match, so do the strings**.

For example, if $b=32$, $h("\verb|CAT|") = 67*32^2 + 65*32^1 + 84 = 70772$. To search for "CAT" we can thus "hash" all 3-char substrings of our text and test the values for equality.

Let's modify this somewhat to make it more useful / appropriate. We need to keep the integer values of some reasonable size (E.g.: No larger than an int or long value), and we need to be able to incrementally update a hash value so that we can progress down a text string looking for a match.

Both of these are taken care of in the **Rabin Karp algorithm**. The hash values are calculated "mod" a large integer, to guarantee that we won't get overflow. Note that due to properties of modulo arithmetic, characters can be "removed" from the beginning of a string almost as easily as they can be "added" to the end. The idea is with each mismatch we "remove" the leftmost character from the hash value and we add the next character from the text to the hash value.

In Rabin Karp, although we are still moving left to right in the text as we mismatch, we are comparing hash values instead of directly comparing characters([RabinKarp.java](handout/RabinKarp.java)).

We know hashing only guarantees no collisions if $h(x)$ is unique for any key and key space is smaller than “table size”. However, this is not practical to implement. So what if a collision occurs? The hash values would match but in fact the strings would not. Should we test for this? As long as the “table size” is very large the probability of a collision is very low. So the algorithm could make a mistake but it is not likely. Alternatively, if hash values match we could verify the result with a char by char test.

If we don’t check for collisions, the algorithm is guaranteed to run in $O(N)$ time and is highly likely to be correct. However, it could fail if a collision occurs. This is called the Monte Carlo version.

If we do check for collisions, the algorithm is highly likely to run in $O(N)$ time. However a worst case could occur if every hash value comparison causes a collision which requires all M characters to be compared, we can get a run-time of $\theta(MN)$. However, the probability of this occurring is EXTREMELY low, since the probability of even one collision is very low. This is called the Las Vegas version.

However, we still haven’t improved on the "normal case" runtime of Brute Force.

## Boyer Moore
What if we took yet another approach? Look at the pattern from right to left instead of left to right. Now, if we mismatch a character early, we have the potential to skip many characters with only one comparison.
Consider the following example: `A = ABCWABCXABCYABCZ`, `P = ABCD`.
If we first compare `D` and `W`, we learn two things:
1. `W` does not match `D`
2. `W` does not appear anywhere in the pattern

Now with one mismatch we can move down the entire length of the pattern (`M` positions). If we know W is not in the pattern, no match could include W, so we can skip past it, we do the same for X, …and so on down the text. ![[Boyer-Moore.png]]
Assuming our search progresses as shown, $\frac{M}{N}$ comparisons are required, given a text of length $N$ and a pattern of length $M$. This is a big improvement over the brute-force algorithm, since it is now a **sub-linear time**. Note that our search will not always progress as shown. But when searching text with a relatively large alphabet, we often encounter characters that do not appear in the pattern. This algorithm allows us to take advantage of this fact.

### Details
The technique we just saw is the **mismatched character** (**MC**) *heuristic*. It is one of two heuristics that make up the Boyer Moore algorithm. The second heuristic takes a different approach and guarantees worst case of $O(N)$.

However, MC doesn't always work so nicely. It depends on the text and pattern. Since we are processing right to left, there are some characters in the text that we don't even look at, and we need to make sure we don't "miss" a potential match.

Consider the following:
	`A = XYXY|X|X|Y|XYYXYXYZXYXYXXYXYYXYXYX`
	`P = XYXY|Z| | |
Now the mismatched character `X` DOES appear in the pattern. So, when "sliding" the pattern to the right, we must make sure not to go farther than where the mismatched character in `A` is first seen (from the right) in `P`. In the first comparison above, '`X`' does not match '`Z`', but it does match an 'X' two positions down (from the right) in `P`. We must be sure not to slide the pattern any further than this amount. Note after the next comparison we can slide only 1 spot.

So how can we figure out how far to skip? We must preprocess the pattern to create a right array. In an array indexed on ALL characters in alphabet, each value will indicate how far we can skip if that character in the text mismatches with the pattern:
```java
for all i right[i] = -1;
for (int j = 0; j < M; j++)
    right[p.charAt(j)] = j;
``` 
The idea is that initially all `char`s in the alphabet are not in the pattern and set to -1
Index increases as characters are found further to the right in the pattern. The larger the value in the right array, the less we can skip.

Now let's see how this will be used:
```Java
 public int search(String txt) {
    int M = pat.length();
    int N = txt.length();
    int skip;
    for (int i = 0; i <= N - M; i += skip) {
       skip = 0;
       for (int j = M-1; j >= 0; j--) {
          if (pat.charAt(j) != txt.charAt(i+j)) {
              skip = Math.max(1, j - right[txt.charAt(i+j)]);
              break;
          }
       }
       if (skip == 0) return i;    // found
    }
    return N;                       // not found
}
```
Note that when `j = M-1`, if `right[X] = -1`, then the skip value is (``(M-1) - (-1)``) = `M`. This is the best case.

But MC can also be poor. Consider this:
`A = XXXXXXXXXXXXXXXXXXXXXXXXXXX`
`P = YXXXX`
Notice that `P` must be completely compared (`M` `char` comps, right to left) before we mismatch and skip. So what do we skip? `skip = Math.max(1, j - right[txt.charAt(i+j)]);` In this case: `j = 0` (we have moved all the way to the left), `right['X'] = 4` (recall how right array is formed), which would give a skip of -4. So the actual skip would be 1 (this is why we have 1 as a second option).

We will then do the same thing again. Thus we do `M` comps, move down 1, `M` comps, move down 1, etc.. We move down ($N-M+1$) times before the pattern will go past the end of the text. This gives a total of $(N-M+1)(M)$ comparisons or $O(MN)$ when $N >> M$. This is bad when compared to Brute Force algorithm's worst case. This is why the BM algorithm has two heuristics. The second heuristic guarantees that the run-time will never be worse than linear. Overall the Boyer Moore algorithm will move down by whichever increment is better. 

See: [Wikipedia Article on Boyer Moore String Search](http://en.wikipedia.org/wiki/Boyer–Moore_string_search_algorithm )


## Summary
|Algorithm|Normal case| Worst case|
|----------|------------|-----------|
|Brute force (naïve algo)|$O(N)$|$O(MN)$, *not likely*|
|Rabin-Karp|$O(N)$|$O(MN)$, *very unlikely* (Las Vegas version)|
|Boyer-Moore|$O(N/M)$ via *Mismatched char*. Note some preprocessing overhead |$O(N)$, guaranteed by second heuristic|
eol 25

---